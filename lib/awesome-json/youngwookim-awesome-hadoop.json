[
  {
    "name": "Apache Hadoop",
    "url": "http://hadoop.apache.org/",
    "description": "Apache Hadoop"
  },
  {
    "name": "Apache Tez",
    "url": "http://tez.apache.org/",
    "description": "A Framework for YARN-based, Data Processing Applications In Hadoop"
  },
  {
    "name": "SpatialHadoop",
    "url": "http://spatialhadoop.cs.umn.edu/",
    "description": "SpatialHadoop is a MapReduce extension to Apache Hadoop designed specially to work with spatial data."
  },
  {
    "name": "GIS Tools for Hadoop",
    "url": "http://esri.github.io/gis-tools-for-hadoop/",
    "description": "Big Data Spatial Analytics for the Hadoop Framework"
  },
  {
    "name": "Elasticsearch Hadoop",
    "url": "https://github.com/elastic/elasticsearch-hadoop",
    "description": "Elasticsearch real-time search and analytics natively integrated with Hadoop. Supports Map/Reduce, Cascading, Apache Hive and Apache Pig."
  },
  {
    "name": "dumbo",
    "url": "https://github.com/klbostee/dumbo",
    "description": "Python module that allows you to easily write and run Hadoop programs."
  },
  {
    "name": "hadoopy",
    "url": "https://github.com/bwhite/hadoopy",
    "description": "Python MapReduce library written in Cython."
  },
  {
    "name": "mrjob",
    "url": "https://github.com/Yelp/mrjob/",
    "description": "mrjob is a Python 2.5+ package that helps you write and run Hadoop Streaming jobs."
  },
  {
    "name": "pydoop",
    "url": "http://pydoop.sourceforge.net/",
    "description": "Pydoop is a package that provides a Python API for Hadoop."
  },
  {
    "name": "hdfs-du",
    "url": "https://github.com/twitter/hdfs-du",
    "description": "HDFS-DU is an interactive visualization of the Hadoop distributed file system."
  },
  {
    "name": "White Elephant",
    "url": "https://github.com/linkedin/white-elephant",
    "description": "Hadoop log aggregator and dashboard"
  },
  {
    "name": "Kiji Project",
    "url": "http://www.kiji.org/"
  },
  {
    "name": "Genie",
    "url": "https://github.com/Netflix/genie",
    "description": "Genie provides REST-ful APIs to run Hadoop, Hive and Pig jobs, and to manage multiple Hadoop resources and perform job submissions across them."
  },
  {
    "name": "Apache Kylin",
    "url": "http://kylin.incubator.apache.org/",
    "description": "Apache Kylin is an open source Distributed Analytics Engine from eBay Inc. that provides SQL interface and multi-dimensional analysis (OLAP) on Hadoop supporting extremely large datasets"
  },
  {
    "name": "Crunch",
    "url": "https://github.com/jondot/crunch",
    "description": "Go-based toolkit for ETL and feature extraction on Hadoop"
  },
  {
    "name": "Apache Ignite",
    "url": "http://ignite.apache.org/",
    "description": "Distributed in-memory platform"
  },
  {
    "name": "Apache Slider",
    "url": "http://slider.incubator.apache.org/",
    "description": "Apache Slider is a project in incubation at the Apache Software Foundation with the goal of making it possible and easy to deploy existing applications onto a YARN cluster."
  },
  {
    "name": "Apache Twill",
    "url": "http://twill.incubator.apache.org/",
    "description": "Apache Twill is an abstraction over Apache Hadoop® YARN that reduces the complexity of developing distributed applications, allowing developers to focus more on their application logic."
  },
  {
    "name": "mpich2-yarn",
    "url": "https://github.com/alibaba/mpich2-yarn",
    "description": "Running MPICH2 on Yarn"
  },
  {
    "name": "Apache HBase",
    "url": "http://hbase.apache.org",
    "description": "Apache HBase"
  },
  {
    "name": "Apache Phoenix",
    "url": "http://phoenix.apache.org/",
    "description": "A SQL skin over HBase supporting secondary indices"
  },
  {
    "name": "happybase",
    "url": "https://github.com/wbolster/happybase",
    "description": "A developer-friendly Python library to interact with Apache HBase."
  },
  {
    "name": "Hannibal",
    "url": "https://github.com/sentric/hannibal",
    "description": "Hannibal is tool to help monitor and maintain HBase-Clusters that are configured for manual splitting."
  },
  {
    "name": "Haeinsa",
    "url": "https://github.com/VCNC/haeinsa",
    "description": "Haeinsa is linearly scalable multi-row, multi-table transaction library for HBase"
  },
  {
    "name": "hindex",
    "url": "https://github.com/Huawei-Hadoop/hindex",
    "description": "Secondary Index for HBase"
  },
  {
    "name": "Apache Accumulo",
    "url": "https://accumulo.apache.org/",
    "description": "The Apache Accumulo™ sorted, distributed key/value store is a robust, scalable, high performance data storage and retrieval system."
  },
  {
    "name": "OpenTSDB",
    "url": "http://opentsdb.net/",
    "description": "The Scalable Time Series Database"
  },
  {
    "name": "Apache Cassandra",
    "url": "http://cassandra.apache.org/"
  },
  {
    "name": "Apache Kudu",
    "url": "https://kudu.apache.org/",
    "description": "Kudu provides a combination of fast inserts/updates and efficient columnar scans to enable multiple real-time analytic workloads across a single storage layer, complementing HDFS and Apache HBase."
  },
  {
    "name": "Apache Hive",
    "url": "http://hive.apache.org",
    "description": "The Apache Hive data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL"
  },
  {
    "name": "Apache Phoenix A SQL skin over HBase supporting secondary indices",
    "url": "http://phoenix.apache.org"
  },
  {
    "name": "Apache HAWQ (incubating)",
    "url": "http://hawq.incubator.apache.org/",
    "description": "Apache HAWQ is a Hadoop native SQL query engine that combines the key technological advantages of MPP database with the scalability and convenience of Hadoop"
  },
  {
    "name": "Lingual",
    "url": "http://www.cascading.org/projects/lingual/",
    "description": "SQL interface for Cascading (MR/Tez job generator)"
  },
  {
    "name": "Cloudera Impala",
    "url": "http://impala.io/"
  },
  {
    "name": "Presto",
    "url": "https://prestodb.io/",
    "description": "Distributed SQL Query Engine for Big Data. Open sourced by Facebook."
  },
  {
    "name": "Apache Tajo",
    "url": "http://tajo.apache.org/",
    "description": "Data warehouse system for Apache Hadoop"
  },
  {
    "name": "Apache Drill",
    "url": "https://drill.apache.org/",
    "description": "Schema-free SQL Query Engine"
  },
  {
    "name": "Apache Trafodion",
    "url": "http://trafodion.apache.org/"
  },
  {
    "name": "Apache Calcite",
    "url": "http://calcite.apache.org/",
    "description": "A Dynamic Data Management Framework"
  },
  {
    "name": "Apache Atlas",
    "url": "http://atlas.incubator.apache.org/",
    "description": "Metadata tagging & lineage capture suppoting complex business data taxonomies"
  },
  {
    "name": "Apache Oozie",
    "url": "http://oozie.apache.org",
    "description": "Apache Oozie"
  },
  {
    "name": "Azkaban",
    "url": "http://azkaban.github.io/"
  },
  {
    "name": "Apache Falcon",
    "url": "http://falcon.apache.org/",
    "description": "Data management and processing platform"
  },
  {
    "name": "Apache NiFi",
    "url": "http://nifi.apache.org/",
    "description": "A dataflow system"
  },
  {
    "name": "Apache AirFlow",
    "url": "https://github.com/apache/incubator-airflow",
    "description": "Airflow is a workflow automation and scheduling system that can be used to author and manage data pipelines"
  },
  {
    "name": "Luigi",
    "url": "http://luigi.readthedocs.org/en/latest/",
    "description": "Python package that helps you build complex pipelines of batch jobs"
  },
  {
    "name": "Apache Flume",
    "url": "http://flume.apache.org",
    "description": "Apache Flume"
  },
  {
    "name": "Suro",
    "url": "https://github.com/Netflix/suro",
    "description": "Netflix's distributed Data Pipeline"
  },
  {
    "name": "Apache Sqoop",
    "url": "http://sqoop.apache.org",
    "description": "Apache Sqoop"
  },
  {
    "name": "Apache Kafka",
    "url": "http://kafka.apache.org/",
    "description": "Apache Kafka"
  },
  {
    "name": "Gobblin from LinkedIn",
    "url": "https://github.com/linkedin/gobblin",
    "description": "Universal data ingestion framework for Hadoop"
  },
  {
    "name": "Apache Pig",
    "url": "http://pig.apache.org",
    "description": "Apache Pig"
  },
  {
    "name": "Apache DataFu",
    "url": "http://datafu.incubator.apache.org/",
    "description": "A collection of libraries for working with large-scale data in Hadoop"
  },
  {
    "name": "vahara",
    "url": "https://github.com/thedatachef/varaha",
    "description": "Machine learning and natural language processing with Apache Pig"
  },
  {
    "name": "packetpig",
    "url": "https://github.com/packetloop/packetpig",
    "description": "Open Source Big Data Security Analytics"
  },
  {
    "name": "akela",
    "url": "https://github.com/mozilla-metrics/akela",
    "description": "Mozilla's utility library for Hadoop, HBase, Pig, etc."
  },
  {
    "name": "seqpig",
    "url": "http://seqpig.sourceforge.net/",
    "description": "Simple and scalable scripting for large sequencing data set(ex: bioinfomation) in Hadoop"
  },
  {
    "name": "Lipstick",
    "url": "https://github.com/Netflix/Lipstick",
    "description": "Pig workflow visualization tool. Introducing Lipstick on A(pache) Pig"
  },
  {
    "name": "PigPen",
    "url": "https://github.com/Netflix/PigPen",
    "description": "PigPen is map-reduce for Clojure, or distributed Clojure. It compiles to Apache Pig, but you don't need to know much about Pig to use it."
  },
  {
    "name": "Kite Software Development Kit",
    "url": "http://kitesdk.org/",
    "description": "A set of libraries, tools, examples, and documentation"
  },
  {
    "name": "gohadoop",
    "url": "https://github.com/hortonworks/gohadoop",
    "description": "Native go clients for Apache Hadoop YARN."
  },
  {
    "name": "Hue",
    "url": "http://gethue.com/",
    "description": "A Web interface for analyzing data with Apache Hadoop."
  },
  {
    "name": "Apache Zeppelin",
    "url": "https://zeppelin.incubator.apache.org/",
    "description": "A web-based notebook that enables interactive data analytics"
  },
  {
    "name": "Jumbune",
    "url": "https://github.com/impetus-opensource/jumbune",
    "description": "Jumbune is an open-source product built for analyzing Hadoop cluster and MapReduce jobs."
  },
  {
    "name": "Apache Thrift",
    "url": "http://thrift.apache.org/"
  },
  {
    "name": "Apache Avro",
    "url": "http://avro.apache.org/",
    "description": "Apache Avro is a data serialization system."
  },
  {
    "name": "Elephant Bird",
    "url": "https://github.com/twitter/elephant-bird",
    "description": "Twitter's collection of LZO and Protocol Buffer-related Hadoop, Pig, Hive, and HBase code."
  },
  {
    "name": "Spring for Apache Hadoop",
    "url": "http://projects.spring.io/spring-hadoop/"
  },
  {
    "name": "hdfs",
    "url": "https://github.com/colinmarc/hdfs",
    "description": "A native go client for HDFS"
  },
  {
    "name": "Oozie Eclipse Plugin",
    "url": "https://marketplace.eclipse.org/content/oozie-eclipse-plugin",
    "description": "A graphical editor for editing Apache Oozie workflows inside Eclipse."
  },
  {
    "name": "Hydrosphere Mist",
    "url": "https://github.com/Hydrospheredata/mist",
    "description": "a service for exposing Apache Spark analytics jobs and machine learning models as realtime, batch or reactive web services."
  },
  {
    "name": "Apache Storm",
    "url": "http://storm.apache.org/"
  },
  {
    "name": "Apache Samza",
    "url": "http://samza.apache.org/"
  },
  {
    "name": "Apache Spark",
    "url": "http://spark.apache.org/streaming/"
  },
  {
    "name": "Apache Flink",
    "url": "https://flink.apache.org/features.html#unified-stream-amp-batch-processing",
    "description": "Apache Flink is a platform for efficient, distributed, general-purpose data processing. It supports exactly once stream processing."
  },
  {
    "name": "Apache Spark",
    "url": "http://spark.apache.org/"
  },
  {
    "name": "Spark Packages",
    "url": "http://spark-packages.org/",
    "description": "A community index of packages for Apache Spark"
  },
  {
    "name": "SparkHub",
    "url": "https://sparkhub.databricks.com/",
    "description": "A community site for Apache Spark"
  },
  {
    "name": "Apache Crunch",
    "url": "http://crunch.apache.org"
  },
  {
    "name": "Cascading",
    "url": "http://www.cascading.org/",
    "description": "Cascading is the proven application development platform for building data applications on Hadoop."
  },
  {
    "name": "Apache Flink",
    "url": "http://flink.apache.org/",
    "description": "Apache Flink is a platform for efficient, distributed, general-purpose data processing."
  },
  {
    "name": "Apache Apex (incubating)",
    "url": "http://apex.incubator.apache.org/",
    "description": "Enterprise-grade unified stream and batch processing engine."
  },
  {
    "name": "Apache Bigtop",
    "url": "http://bigtop.apache.org/",
    "description": "Apache Bigtop: Packaging and tests of the Apache Hadoop ecosystem"
  },
  {
    "name": "Apache Ambari",
    "url": "http://ambari.apache.org/",
    "description": "Apache Ambari"
  },
  {
    "name": "Ganglia Monitoring System",
    "url": "http://ganglia.sourceforge.net/"
  },
  {
    "name": "ankush",
    "url": "https://github.com/impetus-opensource/ankush",
    "description": "A big data cluster management tool that creates and manages clusters of different technologies."
  },
  {
    "name": "Apache Zookeeper",
    "url": "http://zookeeper.apache.org/",
    "description": "Apache Zookeeper"
  },
  {
    "name": "Apache Curator",
    "url": "http://curator.apache.org/",
    "description": "ZooKeeper client wrapper and rich ZooKeeper framework"
  },
  {
    "name": "Buildoop",
    "url": "https://github.com/keedio/buildoop",
    "description": "Hadoop Ecosystem Builder"
  },
  {
    "name": "Deploop",
    "url": "http://deploop.github.io/",
    "description": "The Hadoop Deploy System"
  },
  {
    "name": "Jumbune",
    "url": "http://www.jumbune.org/",
    "description": "An open source MapReduce profiling, MapReduce flow debugging, HDFS data quality validation and Hadoop cluster monitoring tool."
  },
  {
    "name": "inviso",
    "url": "https://github.com/Netflix/inviso",
    "description": "Inviso is a lightweight tool that provides the ability to search for Hadoop jobs, visualize the performance, and view cluster utilization."
  },
  {
    "name": "ElasticSearch",
    "url": "https://www.elastic.co/"
  },
  {
    "name": "Apache Solr",
    "url": "http://lucene.apache.org/solr/"
  },
  {
    "name": "SenseiDB",
    "url": "http://www.senseidb.com/",
    "description": "Open-source, distributed, realtime, semi-structured database"
  },
  {
    "name": "Banana",
    "url": "https://github.com/LucidWorks/banana",
    "description": "Kibana port for Apache Solr"
  },
  {
    "name": "Apache Nutch",
    "url": "http://nutch.apache.org/",
    "description": "Apache Nutch is a highly extensible and scalable open source web crawler software project."
  },
  {
    "name": "Apache Ranger",
    "url": "http://ranger.incubator.apache.org/",
    "description": "Ranger is a framework to enable, monitor and manage comprehensive data security across the Hadoop platform."
  },
  {
    "name": "Apache Sentry",
    "url": "https://sentry.incubator.apache.org/",
    "description": "An authorization module for Hadoop"
  },
  {
    "name": "Apache Knox Gateway",
    "url": "https://knox.apache.org/",
    "description": "A REST API Gateway for interacting with Hadoop clusters."
  },
  {
    "name": "Project Rhino",
    "url": "https://github.com/intel-hadoop/project-rhino",
    "description": "Intel's open source effort to enhance the existing data protection capabilities of the Hadoop ecosystem to address security and compliance challenges, and contribute the code back to Apache."
  },
  {
    "name": "Big Data Benchmark",
    "url": "https://amplab.cs.berkeley.edu/benchmark/"
  },
  {
    "name": "HiBench",
    "url": "https://github.com/intel-hadoop/HiBench"
  },
  {
    "name": "Big-Bench",
    "url": "https://github.com/intel-hadoop/Big-Data-Benchmark-for-Big-Bench"
  },
  {
    "name": "hive-benchmarks",
    "url": "https://github.com/yhuai/hive-benchmarks"
  },
  {
    "name": "hive-testbench",
    "url": "https://github.com/cartershanklin/hive-testbench",
    "description": "Testbench for experimenting with Apache Hive at any data scale."
  },
  {
    "name": "YCSB",
    "url": "https://github.com/brianfrankcooper/YCSB",
    "description": "The Yahoo! Cloud Serving Benchmark (YCSB) is an open-source specification and program suite for evaluating retrieval and maintenance capabilities of computer programs. It is often used to compare relative performance of NoSQL database management systems."
  },
  {
    "name": "Apache Mahout",
    "url": "http://mahout.apache.org"
  },
  {
    "name": "Oryx 2",
    "url": "https://github.com/OryxProject/oryx",
    "description": "Lambda architecture on Spark, Kafka for real-time large scale machine learning"
  },
  {
    "name": "MLlib",
    "url": "https://spark.apache.org/mllib/",
    "description": "MLlib is Apache Spark's scalable machine learning library."
  },
  {
    "name": "R",
    "url": "http://www.r-project.org/",
    "description": "R is a free software environment for statistical computing and graphics."
  },
  {
    "name": "RHadoop including RHDFS, RHBase, RMR2, plyrmr",
    "url": "https://github.com/RevolutionAnalytics/RHadoop/wiki"
  },
  {
    "name": "RHive RHive, for launching Hive queries from R",
    "url": "https://github.com/nexr/RHive"
  },
  {
    "name": "Apache Lens",
    "url": "http://lens.apache.org/"
  },
  {
    "name": "Apache SINGA (incubating)",
    "url": "https://singa.incubator.apache.org/",
    "description": "SINGA is a general distributed deep learning platform for training big deep learning models over large datasets"
  },
  {
    "name": "http://nexr.github.io/hive-udf/",
    "url": "http://nexr.github.io/hive-udf/"
  },
  {
    "name": "https://github.com/edwardcapriolo/hive_cassandra_udfs",
    "url": "https://github.com/edwardcapriolo/hive_cassandra_udfs"
  },
  {
    "name": "https://github.com/livingsocial/HiveSwarm",
    "url": "https://github.com/livingsocial/HiveSwarm"
  },
  {
    "name": "https://github.com/ThinkBigAnalytics/Hive-Extensions-from-Think-Big-Analytics",
    "url": "https://github.com/ThinkBigAnalytics/Hive-Extensions-from-Think-Big-Analytics"
  },
  {
    "name": "https://github.com/karthkk/udfs",
    "url": "https://github.com/karthkk/udfs"
  },
  {
    "name": "https://github.com/twitter/elephant-bird",
    "url": "https://github.com/twitter/elephant-bird",
    "description": "Twitter"
  },
  {
    "name": "https://github.com/lovelysystems/ls-hive",
    "url": "https://github.com/lovelysystems/ls-hive"
  },
  {
    "name": "https://github.com/stewi2/hive-udfs",
    "url": "https://github.com/stewi2/hive-udfs"
  },
  {
    "name": "https://github.com/klout/brickhouse",
    "url": "https://github.com/klout/brickhouse"
  },
  {
    "name": "https://github.com/markgrover/hive-translate (PostgreSQL translate())",
    "url": "https://github.com/markgrover/hive-translate"
  },
  {
    "name": "https://github.com/deanwampler/HiveUDFs",
    "url": "https://github.com/deanwampler/HiveUDFs"
  },
  {
    "name": "https://github.com/myui/hivemall (Machine Learning UDF/UDAF/UDTF)",
    "url": "https://github.com/myui/hivemall"
  },
  {
    "name": "https://github.com/edwardcapriolo/hive-geoip (GeoIP UDF)",
    "url": "https://github.com/edwardcapriolo/hive-geoip"
  },
  {
    "name": "https://github.com/Netflix/Surus",
    "url": "https://github.com/Netflix/Surus"
  },
  {
    "name": "https://github.com/dvasilen/Hive-Cassandra",
    "url": "https://github.com/dvasilen/Hive-Cassandra"
  },
  {
    "name": "https://github.com/yc-huang/Hive-mongo",
    "url": "https://github.com/yc-huang/Hive-mongo"
  },
  {
    "name": "https://github.com/balshor/gdata-storagehandler",
    "url": "https://github.com/balshor/gdata-storagehandler"
  },
  {
    "name": "https://github.com/karthkk/hive-hbase-json",
    "url": "https://github.com/karthkk/hive-hbase-json"
  },
  {
    "name": "https://github.com/sunsuk7tp/hive-hbase-integration",
    "url": "https://github.com/sunsuk7tp/hive-hbase-integration"
  },
  {
    "name": "https://bitbucket.org/rodrigopr/redisstoragehandler",
    "url": "https://bitbucket.org/rodrigopr/redisstoragehandler"
  },
  {
    "name": "https://github.com/zhuguangbin/HiveJDBCStorageHanlder",
    "url": "https://github.com/zhuguangbin/HiveJDBCStorageHanlder"
  },
  {
    "name": "https://github.com/chimpler/hive-solr",
    "url": "https://github.com/chimpler/hive-solr"
  },
  {
    "name": "https://github.com/bfemiano/accumulo-hive-storage-manager",
    "url": "https://github.com/bfemiano/accumulo-hive-storage-manager"
  },
  {
    "name": "https://github.com/rcongiu/Hive-JSON-Serde",
    "url": "https://github.com/rcongiu/Hive-JSON-Serde"
  },
  {
    "name": "https://github.com/mochi/hive-json-serde",
    "url": "https://github.com/mochi/hive-json-serde"
  },
  {
    "name": "https://github.com/ogrodnek/csv-serde",
    "url": "https://github.com/ogrodnek/csv-serde"
  },
  {
    "name": "https://github.com/parag/HiveJsonSerde",
    "url": "https://github.com/parag/HiveJsonSerde"
  },
  {
    "name": "https://github.com/electrum/hive-serde",
    "url": "https://github.com/electrum/hive-serde",
    "description": "JSON"
  },
  {
    "name": "https://github.com/karthkk/hive-hbase-json",
    "url": "https://github.com/karthkk/hive-hbase-json"
  },
  {
    "name": "https://github.com/forward3d/rbhive",
    "url": "https://github.com/forward3d/rbhive"
  },
  {
    "name": "https://github.com/synctree/activerecord-hive-adapter",
    "url": "https://github.com/synctree/activerecord-hive-adapter"
  },
  {
    "name": "https://github.com/hrp/sequel-hive-adapter",
    "url": "https://github.com/hrp/sequel-hive-adapter"
  },
  {
    "name": "https://github.com/forward/node-hive",
    "url": "https://github.com/forward/node-hive"
  },
  {
    "name": "https://github.com/recruitcojp/WebHive",
    "url": "https://github.com/recruitcojp/WebHive"
  },
  {
    "name": "shib",
    "url": "https://github.com/tagomoris/shib",
    "description": "WebUI for query engines: Hive and Presto"
  },
  {
    "name": "clive",
    "url": "https://github.com/bmuller/clive",
    "description": "Clojure library for interacting with Hive via Thrift"
  },
  {
    "name": "https://github.com/anjuke/hwi",
    "url": "https://github.com/anjuke/hwi"
  },
  {
    "name": "https://code.google.com/a/apache-extras.org/p/hipy/",
    "url": "https://code.google.com/a/apache-extras.org/p/hipy/"
  },
  {
    "name": "https://github.com/dmorel/Thrift-API-HiveClient2 (Perl",
    "url": "https://github.com/dmorel/Thrift-API-HiveClient2",
    "description": "HiveServer2)"
  },
  {
    "name": "PyHive",
    "url": "https://github.com/dropbox/PyHive",
    "description": "Python interface to Hive and Presto"
  },
  {
    "name": "https://github.com/recruitcojp/OdbcHive",
    "url": "https://github.com/recruitcojp/OdbcHive"
  },
  {
    "name": "Hive-Sharp",
    "url": "https://bitbucket.org/vadim/hive-sharp"
  },
  {
    "name": "HiveRunner",
    "url": "https://github.com/klarna/HiveRunner",
    "description": "An Open Source unit test framework for hadoop hive queries based on JUnit4"
  },
  {
    "name": "Beetest",
    "url": "https://github.com/kawaa/Beetest",
    "description": "A super simple utility for testing Apache Hive scripts locally for non-Java developers."
  },
  {
    "name": "Hive_test- Unit test framework for hive and hive-service",
    "url": "https://github.com/edwardcapriolo/hive_test"
  },
  {
    "name": "Flume MongoDB Sink",
    "url": "https://github.com/leonlee/flume-ng-mongodb-sink"
  },
  {
    "name": "Flume HornetQ Channel",
    "url": "https://github.com/btoddb/flume-ng-hornetq-channel"
  },
  {
    "name": "Flume MessagePack Source",
    "url": "https://github.com/leonlee/flume-ng-msgpack-source"
  },
  {
    "name": "Flume RabbitMQ source and sink",
    "url": "https://github.com/jcustenborder/flume-ng-rabbitmq"
  },
  {
    "name": "Flume UDP Source",
    "url": "https://github.com/whitepages/flume-udp-source"
  },
  {
    "name": "Stratio Ingestion",
    "url": "https://github.com/Stratio/Ingestion",
    "description": "Custom sinks: Cassandra, MongoDB, Stratio Streaming and JDBC"
  },
  {
    "name": "Flume Custom Serializers",
    "url": "https://github.com/relistan/flume-serializers"
  },
  {
    "name": "Real-time analytics in Apache Flume",
    "url": "https://github.com/jrkinley/flume-interceptor-analytics"
  },
  {
    "name": ".Net FlumeNG Clients",
    "url": "https://github.com/marksl/DotNetFlumeNG.Clients"
  },
  {
    "name": "Hadoop Weekly",
    "url": "http://www.hadoopweekly.com/"
  },
  {
    "name": "The Hadoop Ecosystem Table",
    "url": "http://hadoopecosystemtable.github.io/"
  },
  {
    "name": "Hadoop 1.x vs 2",
    "url": "http://www.slideshare.net/RommelGarcia2/hadoop-1x-vs-2"
  },
  {
    "name": "Apache Hadoop YARN: Yet Another Resource Negotiator",
    "url": "http://www.socc2013.org/home/program/a5-vavilapalli.pdf"
  },
  {
    "name": "Introducing Apache Hadoop YARN",
    "url": "http://hortonworks.com/blog/introducing-apache-hadoop-yarn/"
  },
  {
    "name": "Apache Hadoop YARN",
    "url": "http://hortonworks.com/blog/apache-hadoop-yarn-background-and-an-overview/",
    "description": "Background and an Overview"
  },
  {
    "name": "Apache Hadoop YARN",
    "url": "http://hortonworks.com/blog/apache-hadoop-yarn-concepts-and-applications/",
    "description": "Concepts and Applications"
  },
  {
    "name": "Apache Hadoop YARN",
    "url": "http://hortonworks.com/blog/apache-hadoop-yarn-resourcemanager/",
    "description": "ResourceManager"
  },
  {
    "name": "Apache Hadoop YARN",
    "url": "http://hortonworks.com/blog/apache-hadoop-yarn-nodemanager/",
    "description": "NodeManager"
  },
  {
    "name": "Migrating to MapReduce 2 on YARN (For Users)",
    "url": "http://blog.cloudera.com/blog/2013/11/migrating-to-mapreduce-2-on-yarn-for-users/"
  },
  {
    "name": "Migrating to MapReduce 2 on YARN (For Operators)",
    "url": "http://blog.cloudera.com/blog/2013/11/migrating-to-mapreduce-2-on-yarn-for-operators/"
  },
  {
    "name": "Hadoop and Big Data: Use Cases at Salesforce.com",
    "url": "https://developer.salesforce.com/blogs/engineering/2013/03/hadoop-use-cases-at-salesforce-com.html"
  },
  {
    "name": "All you wanted to know about Hadoop, but were too afraid to ask: genealogy of elephants.",
    "url": "https://blogs.apache.org/bigtop/entry/all_you_wanted_to_know"
  },
  {
    "name": "What is Bigtop, and Why Should You Care?",
    "url": "https://blogs.apache.org/bigtop/entry/bigtop_and_why_should_you"
  },
  {
    "name": "Hadoop",
    "url": "http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support",
    "description": "Distributions and Commercial Support"
  },
  {
    "name": "Ganglia configuration for a small Hadoop cluster and some troubleshooting",
    "url": "http://hakunamapdata.com/ganglia-configuration-for-a-small-hadoop-cluster-and-some-troubleshooting/"
  },
  {
    "name": "Hadoop illuminated",
    "url": "http://hadoopilluminated.com/",
    "description": "Open Source Hadoop Book"
  },
  {
    "name": "NoSQL Database",
    "url": "http://nosql-database.org/"
  },
  {
    "name": "10 Best Practices for Apache Hive",
    "url": "https://www.qubole.com/blog/big-data/hive-best-practices/"
  },
  {
    "name": "Hadoop Operations at Scale",
    "url": "http://hortonworks.com/blog/apache-hadoop-operations-scale/"
  },
  {
    "name": "AWS BigData Blog",
    "url": "http://blogs.aws.amazon.com/bigdata/"
  },
  {
    "name": "Hadoop360",
    "url": "http://www.hadoop360.com/"
  },
  {
    "name": "How to monitor Hadoop metrics",
    "url": "https://www.datadoghq.com/blog/monitor-hadoop-metrics/"
  },
  {
    "name": "Hadoop Summit Presentations",
    "url": "http://www.slideshare.net/Hadoop_Summit",
    "description": "Slide decks from Hadoop Summit"
  },
  {
    "name": "Hadoop 24/7",
    "url": "http://www.slideshare.net/allenwittenauer/aw-apachecon2009-15342917"
  },
  {
    "name": "An example Apache Hadoop Yarn upgrade",
    "url": "http://www.slideshare.net/mikejf12/an-example-apache-hadoop-yarn-upgrade"
  },
  {
    "name": "Apache Hadoop In Theory And Practice",
    "url": "http://www.slideshare.net/AdamKawa/hadoop-intheoryandpractice"
  },
  {
    "name": "Hadoop Operations at LinkedIn",
    "url": "http://www.slideshare.net/allenwittenauer/2013-hadoopsummitemea"
  },
  {
    "name": "Hadoop Performance at LinkedIn",
    "url": "http://www.slideshare.net/allenwittenauer/2012-lihadoopperf"
  },
  {
    "name": "Docker based Hadoop provisioning",
    "url": "http://www.slideshare.net/JanosMatyas/docker-based-hadoop-provisioning"
  },
  {
    "name": "Hadoop: The Definitive Guide",
    "url": "http://www.amazon.com/gp/product/1449311520/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1449311520&linkCode=as2&tag=matratsblo-20"
  },
  {
    "name": "Hadoop Operations",
    "url": "http://www.amazon.com/gp/product/1449327052/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1449327052&linkCode=as2&tag=matratsblo-20"
  },
  {
    "name": "Apache Hadoop Yarn",
    "url": "http://www.amazon.com/dp/0321934504?tag=matratsblo-20"
  },
  {
    "name": "HBase: The Definitive Guide",
    "url": "http://shop.oreilly.com/product/0636920014348.do"
  },
  {
    "name": "Programming Pig",
    "url": "http://shop.oreilly.com/product/0636920018087.do"
  },
  {
    "name": "Programming Hive",
    "url": "http://shop.oreilly.com/product/0636920023555.do"
  },
  {
    "name": "Hadoop in Practice, Second Edition",
    "url": "http://www.manning.com/holmes2/"
  },
  {
    "name": "Hadoop in Action, Second Edition",
    "url": "http://www.manning.com/lam2/"
  },
  {
    "name": "ApacheCon",
    "url": "http://www.apachecon.com/"
  },
  {
    "name": "Strata + Hadoop World",
    "url": "http://conferences.oreilly.com/strata"
  },
  {
    "name": "Hadoop Summit",
    "url": "http://hadoopsummit.org/"
  }
]
