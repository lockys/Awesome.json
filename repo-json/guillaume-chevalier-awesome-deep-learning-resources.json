[
  {
    "name": "Deep Learning Specialization by Andrew Ng on Coursera",
    "url": "https://www.coursera.org/specializations/deep-learning",
    "description": "New series of 5 Deep Learning courses by Andrew Ng, now with Python rather than Matlab/Octave, and which leads to a specialization certificate."
  },
  {
    "name": "Deep Learning by Google",
    "url": "https://www.udacity.com/course/deep-learning--ud730",
    "description": "Good intermediate to advanced-level course covering high-level deep learning concepts, I found it helps to get creative once the basics are acquired."
  },
  {
    "name": "Machine Learning for Trading by Georgia Tech",
    "url": "https://www.udacity.com/course/machine-learning-for-trading--ud501",
    "description": "Interesting class for acquiring basic knowledge of machine learning applied to trading and some AI and finance concepts. I especially liked the section on Q-Learning."
  },
  {
    "name": "Neural networks class by Hugo Larochelle, Université de Sherbrooke",
    "url": "https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH",
    "description": "Interesting class about neural networks available online for free by Hugo Larochelle, yet I have watched a few of those videos."
  },
  {
    "name": "GLO-4030/7030 Apprentissage par réseaux de neurones profonds",
    "url": "https://ulaval-damas.github.io/glo4030/",
    "description": "This is a class given by Philippe Giguère, Professor at University Laval. I especially found awesome its rare visualization of the multi-head attention mechanism, which can be contemplated at the slide 28 of week 13's class."
  },
  {
    "name": "Neural Networks and Deep Learning",
    "url": "http://neuralnetworksanddeeplearning.com/index.html",
    "description": "This book covers many of the core concepts behind neural networks and deep learning."
  },
  {
    "name": "Deep Learning",
    "url": "http://www.deeplearningbook.org/",
    "description": "An MIT Press book - Yet halfway through the book, it contains satisfying math content on how to think about actual deep learning."
  },
  {
    "name": "Some other books I have read",
    "url": "https://books.google.ca/books?hl=en&as_coll=4&num=10&uid=103409002069648430166&source=gbs_slider_cls_metadata_4_mylibrary_title",
    "description": "Some books listed here are less related to deep learning but are still somehow relevant to this list."
  },
  {
    "name": "The Unreasonable Effectiveness of Recurrent Neural Networks",
    "url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/",
    "description": "MUST READ post by Andrej Karpathy - this is what motivated me to learn RNNs, it demonstrates what it can achieve in the most basic form of NLP."
  },
  {
    "name": "Neural Networks, Manifolds, and Topology",
    "url": "http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/",
    "description": "Fresh look on how neurons map information."
  },
  {
    "name": "Understanding LSTM Networks",
    "url": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/",
    "description": "Explains the LSTM cells' inner workings, plus, it has interesting links in conclusion."
  },
  {
    "name": "Attention and Augmented Recurrent Neural Networks",
    "url": "http://distill.pub/2016/augmented-rnns/",
    "description": "Interesting for visual animations, it is a nice intro to attention mechanisms as an example."
  },
  {
    "name": "Recommending music on Spotify with deep learning",
    "url": "http://benanne.github.io/2014/08/05/spotify-cnns.html",
    "description": "Awesome for doing clustering on audio - post by an intern at Spotify."
  },
  {
    "name": "Announcing SyntaxNet: The World’s Most Accurate Parser Goes Open Source",
    "url": "https://research.googleblog.com/2016/05/announcing-syntaxnet-worlds-most.html",
    "description": "Parsey McParseface's birth, a neural syntax tree parser."
  },
  {
    "name": "Improving Inception and Image Classification in TensorFlow",
    "url": "https://research.googleblog.com/2016/08/improving-inception-and-image.html",
    "description": "Very interesting CNN architecture (e.g.: the inception-style convolutional layers is promising and efficient in terms of reducing the number of parameters)."
  },
  {
    "name": "WaveNet: A Generative Model for Raw Audio",
    "url": "https://deepmind.com/blog/wavenet-generative-model-raw-audio/",
    "description": "Realistic talking machines: perfect voice generation."
  },
  {
    "name": "François Chollet's Twitter",
    "url": "https://twitter.com/fchollet",
    "description": "Author of Keras - has interesting Twitter posts and innovative ideas."
  },
  {
    "name": "Neuralink and the Brain’s Magical Future",
    "url": "http://waitbutwhy.com/2017/04/neuralink.html",
    "description": "Thought provoking article about the future of the brain and brain-computer interfaces."
  },
  {
    "name": "Migrating to Git LFS for Developing Deep Learning Applications with Large Files",
    "url": "http://vooban.com/en/tips-articles-geek-stuff/migrating-to-git-lfs-for-developing-deep-learning-applications-with-large-files/",
    "description": "Easily manage huge files in your private Git projects."
  },
  {
    "name": "The future of deep learning",
    "url": "https://blog.keras.io/the-future-of-deep-learning.html",
    "description": "François Chollet's thoughts on the future of deep learning."
  },
  {
    "name": "Discover structure behind data with decision trees",
    "url": "http://vooban.com/en/tips-articles-geek-stuff/discover-structure-behind-data-with-decision-trees/",
    "description": "Grow decision trees and visualize them, infer the hidden logic behind data."
  },
  {
    "name": "Hyperopt tutorial for Optimizing Neural Networks’ Hyperparameters",
    "url": "http://vooban.com/en/tips-articles-geek-stuff/hyperopt-tutorial-for-optimizing-neural-networks-hyperparameters/",
    "description": "Learn to slay down hyperparameter spaces automatically rather than by hand."
  },
  {
    "name": "Estimating an Optimal Learning Rate For a Deep Neural Network",
    "url": "https://medium.com/@surmenok/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0",
    "description": "Clever trick to estimate an optimal learning rate prior any single full training."
  },
  {
    "name": "skflow",
    "url": "https://github.com/tensorflow/skflow",
    "description": "TensorFlow wrapper à la scikit-learn."
  },
  {
    "name": "Keras",
    "url": "https://keras.io/",
    "description": "Keras is another intersting deep learning framework like TensorFlow, it is mostly high-level."
  },
  {
    "name": "carpedm20's repositories",
    "url": "https://github.com/carpedm20",
    "description": "Many interesting neural network architectures are implemented by the Korean guy Taehoon Kim, A.K.A. carpedm20."
  },
  {
    "name": "carpedm20/NTM-tensorflow",
    "url": "https://github.com/carpedm20/NTM-tensorflow",
    "description": "Neural Turing Machine TensorFlow implementation."
  },
  {
    "name": "Deep learning for lazybones",
    "url": "http://oduerr.github.io/blog/2016/04/06/Deep-Learning_for_lazybones",
    "description": "Transfer learning tutorial in TensorFlow for vision from high-level embeddings of a pretrained CNN, AlexNet 2012."
  },
  {
    "name": "LSTM for Human Activity Recognition (HAR)",
    "url": "https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition",
    "description": "Tutorial of mine on using LSTMs on time series for classification."
  },
  {
    "name": "Deep stacked residual bidirectional LSTMs for HAR",
    "url": "https://github.com/guillaume-chevalier/HAR-stacked-residual-bidir-LSTMs",
    "description": "Improvements on the previous project."
  },
  {
    "name": "Sequence to Sequence (seq2seq) Recurrent Neural Network (RNN) for Time Series Prediction",
    "url": "https://github.com/guillaume-chevalier/seq2seq-signal-prediction",
    "description": "Tutorial of mine on how to predict temporal sequences of numbers - that may be multichannel."
  },
  {
    "name": "Hyperopt for a Keras CNN on CIFAR-100",
    "url": "https://github.com/Vooban/Hyperopt-Keras-CNN-CIFAR-100",
    "description": "Auto (meta) optimizing a neural net (and its architecture) on the CIFAR-100 dataset."
  },
  {
    "name": "ML / DL repositories I starred",
    "url": "https://github.com/guillaume-chevalier?direction=desc&page=1&q=machine+OR+deep+OR+learning+OR+rnn+OR+lstm+OR+cnn&sort=stars&tab=stars&utf8=%E2%9C%93",
    "description": "GitHub is full of nice code samples & projects."
  },
  {
    "name": "Smoothly Blend Image Patches",
    "url": "https://github.com/Vooban/Smoothly-Blend-Image-Patches",
    "description": "Smooth patch merger for semantic segmentation with a U-Net."
  },
  {
    "name": "Cornell Movie--Dialogs Corpus",
    "url": "http://www.cs.cornell.edu/%7Ecristian/Cornell_Movie-Dialogs_Corpus.html",
    "description": "This could be used for a chatbot."
  },
  {
    "name": "SQuAD The Stanford Question Answering Dataset",
    "url": "https://rajpurkar.github.io/SQuAD-explorer/",
    "description": "Question answering dataset that can be explored online, and a list of models performing well on that dataset."
  },
  {
    "name": "LibriSpeech ASR corpus",
    "url": "http://www.openslr.org/12/",
    "description": "Huge free English speech dataset with balanced genders and speakers, that seems to be of high quality."
  },
  {
    "name": "Awesome Public Datasets",
    "url": "https://github.com/caesar0301/awesome-public-datasets",
    "description": "An awesome list of public datasets."
  },
  {
    "name": "Neural Networks and Deep Learning, ch.4",
    "url": "http://neuralnetworksanddeeplearning.com/chap4.html",
    "description": "A visual proof that neural nets can compute any function."
  },
  {
    "name": "Yes you should understand backprop",
    "url": "https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#.mr5wq61fb",
    "description": "Exposing backprop's caveats and the importance of knowing that while training models."
  },
  {
    "name": "Artificial Neural Networks: Mathematics of Backpropagation",
    "url": "http://briandolhansky.com/blog/2013/9/27/artificial-neural-networks-backpropagation-part-4",
    "description": "Picturing backprop, mathematically."
  },
  {
    "name": "Deep Learning Lecture 12: Recurrent Neural Nets and LSTMs",
    "url": "https://www.youtube.com/watch?v=56TYLaQN4N8",
    "description": "Unfolding of RNN graphs is explained properly, and potential problems about gradient descent algorithms are exposed."
  },
  {
    "name": "Gradient descent algorithms in a saddle point",
    "url": "http://sebastianruder.com/content/images/2016/09/saddle_point_evaluation_optimizers.gif",
    "description": "Visualize how different optimizers interacts with a saddle points."
  },
  {
    "name": "Gradient descent algorithms in an almost flat landscape",
    "url": "https://devblogs.nvidia.com/wp-content/uploads/2015/12/NKsFHJb.gif",
    "description": "Visualize how different optimizers interacts with an almost flat landscape."
  },
  {
    "name": "Gradient Descent",
    "url": "https://www.youtube.com/watch?v=F6GSRDoB-Cg",
    "description": "Okay, I already listed Andrew NG's Coursera class above, but this video especially is quite pertinent as an introduction and defines the gradient descent algorithm."
  },
  {
    "name": "Gradient Descent: Intuition",
    "url": "https://www.youtube.com/watch?v=YovTqTY-PYY",
    "description": "What follows from the previous video: now add intuition."
  },
  {
    "name": "Gradient Descent in Practice 2: Learning Rate",
    "url": "https://www.youtube.com/watch?v=gX6fZHgfrow",
    "description": "How to adjust the learning rate of a neural network."
  },
  {
    "name": "The Problem of Overfitting",
    "url": "https://www.youtube.com/watch?v=u73PU6Qwl1I",
    "description": "A good explanation of overfitting and how to address that problem."
  },
  {
    "name": "Diagnosing Bias vs Variance",
    "url": "https://www.youtube.com/watch?v=ewogYw5oCAI",
    "description": "Understanding bias and variance in the predictions of a neural net and how to address those problems."
  },
  {
    "name": "Self-Normalizing Neural Networks",
    "url": "https://arxiv.org/pdf/1706.02515.pdf",
    "description": "Appearance of the incredible SELU activation function."
  },
  {
    "name": "Learning to learn by gradient descent by gradient descent",
    "url": "https://arxiv.org/pdf/1606.04474.pdf",
    "description": "RNN as an optimizer: introducing the L2L optimizer, a meta-neural network."
  },
  {
    "name": "MathBox, Tools for Thought Graphical Algebra and Fourier Analysis",
    "url": "https://acko.net/files/gltalks/toolsforthought/",
    "description": "New look on Fourier analysis."
  },
  {
    "name": "How to Fold a Julia Fractal",
    "url": "http://acko.net/blog/how-to-fold-a-julia-fractal/",
    "description": "Animations dealing with complex numbers and wave equations."
  },
  {
    "name": "Animate Your Way to Glory, Math and Physics in Motion",
    "url": "http://acko.net/blog/animate-your-way-to-glory/",
    "description": "Convergence methods in physic engines, and applied to interaction design."
  },
  {
    "name": "Animate Your Way to Glory",
    "url": "http://acko.net/blog/animate-your-way-to-glory-pt2/",
    "description": "Part II, Math and Physics in Motion - Nice animations for rotation and rotation interpolation with Quaternions, a mathematical object for handling 3D rotations."
  },
  {
    "name": "Filtering signal, plotting the STFT and the Laplace transform",
    "url": "https://github.com/guillaume-chevalier/filtering-stft-and-laplace-transform",
    "description": "Simple Python demo on signal processing."
  },
  {
    "name": "Bidirectional Recurrent Neural Networks",
    "url": "http://www.di.ufpe.br/%7Efnj/RNA/bibliografia/BRNN.pdf",
    "description": "Better classifications with RNNs with bidirectional scanning on the time axis."
  },
  {
    "name": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "url": "https://arxiv.org/pdf/1406.1078v3.pdf",
    "description": "Two networks in one combined into a seq2seq (sequence to sequence) Encoder-Decoder architecture. RNN Encoder–Decoder with 1000 hidden units. Adadelta optimizer."
  },
  {
    "name": "Sequence to Sequence Learning with Neural Networks",
    "url": "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf",
    "description": "4 stacked LSTM cells of 1000 hidden size with reversed input sentences, and with beam search, on the WMT’14 English to French dataset."
  },
  {
    "name": "Exploring the Limits of Language Modeling",
    "url": "https://arxiv.org/pdf/1602.02410.pdf",
    "description": "Nice recursive models using word-level LSTMs on top of a character-level CNN using an overkill amount of GPU power."
  },
  {
    "name": "Neural Machine Translation and Sequence-to-sequence Models: A Tutorial",
    "url": "https://arxiv.org/pdf/1703.01619.pdf",
    "description": "Interesting overview of the subject of NMT, I mostly read part 8 about RNNs with attention as a refresher."
  },
  {
    "name": "Exploring the Depths of Recurrent Neural Networks with Stochastic Residual Learning",
    "url": "https://cs224d.stanford.edu/reports/PradhanLongpre.pdf",
    "description": "Basically, residual connections can be better than stacked RNNs in the presented case of sentiment analysis."
  },
  {
    "name": "Pixel Recurrent Neural Networks",
    "url": "https://arxiv.org/pdf/1601.06759.pdf",
    "description": "Nice for photoshop-like \"content aware fill\" to fill missing patches in images."
  },
  {
    "name": "Adaptive Computation Time for Recurrent Neural Networks",
    "url": "https://arxiv.org/pdf/1603.08983v4.pdf",
    "description": "Let RNNs decide how long they compute. I would love to see how well would it combines to Neural Turing Machines. Interesting interactive visualizations on the subject can be found here."
  },
  {
    "name": "ImageNet Classification with Deep Convolutional Neural Networks",
    "url": "http://www.cs.toronto.edu/%7Efritz/absps/imagenet.pdf",
    "description": "AlexNet, 2012 ILSVRC, breakthrough of the ReLU activation function."
  },
  {
    "name": "Visualizing and Understanding Convolutional Networks",
    "url": "https://arxiv.org/pdf/1311.2901v3.pdf",
    "description": "For the \"deconvnet layer\"."
  },
  {
    "name": "Fast and Accurate Deep Network Learning by Exponential Linear Units",
    "url": "https://arxiv.org/pdf/1511.07289v1.pdf",
    "description": "ELU activation function for CIFAR vision tasks."
  },
  {
    "name": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "url": "https://arxiv.org/pdf/1409.1556v6.pdf",
    "description": "Interesting idea of stacking multiple 3x3 conv+ReLU before pooling for a bigger filter size with just a few parameters. There is also a nice table for \"ConvNet Configuration\"."
  },
  {
    "name": "Going Deeper with Convolutions",
    "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf",
    "description": "GoogLeNet: Appearance of \"Inception\" layers/modules, the idea is of parallelizing conv layers into many mini-conv of different size with \"same\" padding, concatenated on depth."
  },
  {
    "name": "Highway Networks",
    "url": "https://arxiv.org/pdf/1505.00387v2.pdf",
    "description": "Highway networks: residual connections."
  },
  {
    "name": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
    "url": "https://arxiv.org/pdf/1502.03167v3.pdf",
    "description": "Batch normalization (BN): to normalize a layer's output by also summing over the entire batch, and then performing a linear rescaling and shifting of a certain trainable amount."
  },
  {
    "name": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
    "url": "https://arxiv.org/pdf/1505.04597.pdf",
    "description": "The U-Net is an encoder-decoder CNN that also has skip-connections, good for image segmentation at a per-pixel level."
  },
  {
    "name": "Deep Residual Learning for Image Recognition",
    "url": "https://arxiv.org/pdf/1512.03385v1.pdf",
    "description": "Very deep residual layers with batch normalization layers - a.k.a. \"how to overfit any vision dataset with too many layers and make any vision model work properly at recognition given enough data\"."
  },
  {
    "name": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",
    "url": "https://arxiv.org/pdf/1602.07261v2.pdf",
    "description": "For improving GoogLeNet with residual connections."
  },
  {
    "name": "WaveNet: a Generative Model for Raw Audio",
    "url": "https://arxiv.org/pdf/1609.03499v2.pdf",
    "description": "Epic raw voice/music generation with new architectures based on dilated causal convolutions to capture more audio length."
  },
  {
    "name": "Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling",
    "url": "https://arxiv.org/pdf/1610.07584v2.pdf",
    "description": "3D-GANs for 3D model generation and fun 3D furniture arithmetics from embeddings (think like word2vec word arithmetics with 3D furniture representations)."
  },
  {
    "name": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour",
    "url": "https://research.fb.com/publications/ImageNet1kIn1h/",
    "description": "Incredibly fast distributed training of a CNN."
  },
  {
    "name": "Densely Connected Convolutional Networks",
    "url": "https://arxiv.org/pdf/1608.06993.pdf",
    "description": "Best Paper Award at CVPR 2017, yielding improvements on state-of-the-art performances on CIFAR-10, CIFAR-100 and SVHN datasets, this new neural network architecture is named DenseNet."
  },
  {
    "name": "The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation",
    "url": "https://arxiv.org/pdf/1611.09326.pdf",
    "description": "Merges the ideas of the U-Net and the DenseNet, this new neural network is especially good for huge datasets in image segmentation."
  },
  {
    "name": "Prototypical Networks for Few-shot Learning",
    "url": "https://arxiv.org/pdf/1703.05175.pdf",
    "description": "Use a distance metric in the loss to determine to which class does an object belongs to from a few examples."
  },
  {
    "name": "Neural Turing Machines",
    "url": "https://arxiv.org/pdf/1410.5401v2.pdf",
    "description": "Outstanding for letting a neural network learn an algorithm with seemingly good generalization over long time dependencies. Sequences recall problem."
  },
  {
    "name": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",
    "url": "https://arxiv.org/pdf/1502.03044.pdf",
    "description": "LSTMs' attention mechanisms on CNNs feature maps does wonders."
  },
  {
    "name": "Teaching Machines to Read and Comprehend",
    "url": "https://arxiv.org/pdf/1506.03340v3.pdf",
    "description": "A very interesting and creative work about textual question answering, what a breakthrough, there is something to do with that."
  },
  {
    "name": "Effective Approaches to Attention-based Neural Machine Translation",
    "url": "https://arxiv.org/pdf/1508.04025.pdf",
    "description": "Exploring different approaches to attention mechanisms."
  },
  {
    "name": "Matching Networks for One Shot Learning",
    "url": "https://arxiv.org/pdf/1606.04080.pdf",
    "description": "Interesting way of doing one-shot learning with low-data by using an attention mechanism and a query to compare an image to other images for classification."
  },
  {
    "name": "Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
    "url": "https://arxiv.org/pdf/1609.08144.pdf",
    "description": "In 2016: stacked residual LSTMs with attention mechanisms on encoder/decoder are the best for NMT (Neural Machine Translation)."
  },
  {
    "name": "Hybrid computing using a neural network with dynamic external memory",
    "url": "http://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz",
    "description": "Improvements on differentiable memory based on NTMs: now it is the Differentiable Neural Computer (DNC)."
  },
  {
    "name": "Massive Exploration of Neural Machine Translation Architectures",
    "url": "https://arxiv.org/pdf/1703.03906.pdf",
    "description": "That yields intuition about the boundaries of what works for doing NMT within a framed seq2seq problem formulation."
  },
  {
    "name": "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram\nPredictions",
    "url": "https://arxiv.org/pdf/1712.05884.pdf",
    "description": "A WaveNet used as a vocoder can be conditioned on generated Mel Spectrograms from the Tacotron 2 LSTM neural network with attention to generate neat audio from text."
  },
  {
    "name": "Tensor Calculus and the Calculus of Moving Surfaces",
    "url": "https://www.youtube.com/playlist?list=PLlXfTHzgMRULkodlIEqfgTS-H1AY_bNtq",
    "description": "Generalize properly how Tensors work, yet just watching a few videos already helps a lot to grasp the concepts."
  },
  {
    "name": "Deep Learning & Machine Learning (Advanced topics)",
    "url": "https://www.youtube.com/playlist?list=PLlp-GWNOd6m4C_-9HxuHg2_ZeI2Yzwwqt",
    "description": "A list of videos about deep learning that I found interesting or useful, this is a mix of a bit of everything."
  },
  {
    "name": "Signal Processing Playlist",
    "url": "https://www.youtube.com/playlist?list=PLlp-GWNOd6m6gSz0wIcpvl4ixSlS-HEmr",
    "description": "A YouTube playlist I composed about DFT/FFT, STFT and the Laplace transform - I was mad about my software engineering bachelor not including signal processing classes (except a bit in the quantum physics class)."
  },
  {
    "name": "Computer Science",
    "url": "https://www.youtube.com/playlist?list=PLlp-GWNOd6m7vLOsW20xAJ81-65C-Ys6k",
    "description": "Yet another YouTube playlist I composed, this time about various CS topics."
  },
  {
    "name": "Siraj's Channel",
    "url": "https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A/videos?view=0&sort=p&flow=grid",
    "description": "Siraj has entertaining, fast-paced video tutorials about deep learning."
  },
  {
    "name": "Two Minute Papers' Channel",
    "url": "https://www.youtube.com/user/keeroyz/videos?sort=p&view=0&flow=grid",
    "description": "Interesting and shallow overview of some research papers, for example about WaveNet or Neural Style Transfer."
  },
  {
    "name": "Geoffrey Hinton interview",
    "url": "https://www.coursera.org/learn/neural-networks-deep-learning/lecture/dcm5r/geoffrey-hinton-interview",
    "description": "Andrew Ng interviews Geoffrey Hinton, who talks about his research and breaktroughs, and gives advice for students."
  },
  {
    "name": "DataTau",
    "url": "http://www.datatau.com/",
    "description": "This is a hub similar to Hacker News, but specific to data science."
  },
  {
    "name": "Naver",
    "url": "http://www.naver.com/",
    "description": "This is a Korean search engine - best used with Google Translate, ironically. Surprisingly, sometimes deep learning search results and comprehensible advanced math content shows up more easily there than on Google search."
  },
  {
    "name": "Arxiv Sanity Preserver",
    "url": "http://www.arxiv-sanity.com/",
    "description": "arXiv browser with TF/IDF features."
  }
]
