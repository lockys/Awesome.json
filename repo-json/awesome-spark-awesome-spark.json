[
  {
    "name": "Flambo ",
    "url": "https://github.com/yieldbot/flambo",
    "description": "Clojure DSL."
  },
  {
    "name": "Mobius ",
    "url": "https://github.com/Microsoft/Mobius",
    "description": "C# bindings (Deprecated in favor of .NET for Apache Spark)."
  },
  {
    "name": ".NET for Apache Spark ",
    "url": "https://github.com/dotnet/spark",
    "description": ".NET bindings."
  },
  {
    "name": "sparklyr ",
    "url": "https://github.com/rstudio/sparklyr",
    "description": "An alternative R backend, using dplyr."
  },
  {
    "name": "sparkle ",
    "url": "https://github.com/tweag/sparkle",
    "description": "Haskell on Apache Spark."
  },
  {
    "name": "almond ",
    "url": "https://almond.sh/",
    "description": "A scala kernel for Jupyter."
  },
  {
    "name": "Apache Zeppelin ",
    "url": "https://zeppelin.incubator.apache.org/",
    "description": "Web-based notebook that enables interactive data analytics with plugable backends, integrated plotting, and extensive Spark support out-of-the-box."
  },
  {
    "name": "Polynote  ",
    "url": "https://polynote.org/",
    "description": "Polynote: an IDE-inspired polyglot notebook. It supports mixing multiple languages in one notebook, and sharing data between them seamlessly. It encourages reproducible notebooks with its immutable data model. Orginating from Netflix."
  },
  {
    "name": "Spark Notebook ",
    "url": "https://github.com/andypetrella/spark-notebook",
    "description": "Scalable and stable Scala and Spark focused notebook bridging the gap between JVM and Data Scientists (incl. extendable, typesafe and reactive charts)."
  },
  {
    "name": "sparkmagic ",
    "url": "https://github.com/jupyter-incubator/sparkmagic",
    "description": "Jupyter magics and kernels for working with remote Spark clusters, for interactively working with remote Spark clusters through Livy, in Jupyter notebooks."
  },
  {
    "name": "Succinct",
    "url": "http://succinct.cs.berkeley.edu/",
    "description": "Support for efficient queries on compressed data."
  },
  {
    "name": "itachi ",
    "url": "https://github.com/yaooqinn/itachi",
    "description": "A library that brings useful functions from modern database management systems to Apache Spark."
  },
  {
    "name": "Spark CSV ",
    "url": "https://github.com/databricks/spark-csv",
    "description": "CSV reader and writer (obsolete since Spark 2.0 [SPARK-12833])."
  },
  {
    "name": "Spark Avro ",
    "url": "https://github.com/databricks/spark-avro",
    "description": "Apache Avro reader and writer (obselete since Spark 2.4 [SPARK-24768])."
  },
  {
    "name": "Spark XML ",
    "url": "https://github.com/databricks/spark-xml",
    "description": "XML parser and writer."
  },
  {
    "name": "Spark-Mongodb ",
    "url": "https://github.com/Stratio/Spark-MongoDB",
    "description": "MongoDB reader and writer."
  },
  {
    "name": "Spark Cassandra Connector ",
    "url": "https://github.com/datastax/spark-cassandra-connector",
    "description": "Cassandra support including data source and API and support for arbitrary queries."
  },
  {
    "name": "Spark Riak Connector ",
    "url": "https://github.com/basho/spark-riak-connector",
    "description": "Riak TS & Riak KV connector."
  },
  {
    "name": "Mongo-Spark ",
    "url": "https://github.com/mongodb/mongo-spark",
    "description": "Official MongoDB connector."
  },
  {
    "name": "OrientDB-Spark ",
    "url": "https://github.com/orientechnologies/spark-orientdb",
    "description": "Official OrientDB connector."
  },
  {
    "name": "Delta Lake ",
    "url": "https://github.com/delta-io/delta",
    "description": "Storage layer with ACID transactions."
  },
  {
    "name": "ADAM ",
    "url": "https://github.com/bigdatagenomics/adam",
    "description": "Set of tools designed to analyse genomics data."
  },
  {
    "name": "Hail ",
    "url": "https://github.com/hail-is/hail",
    "description": "Genetic analysis framework."
  },
  {
    "name": "Magellan ",
    "url": "https://github.com/harsha2010/magellan",
    "description": "Geospatial analytics using Spark."
  },
  {
    "name": "GeoSpark ",
    "url": "https://github.com/Sarwat/GeoSpark",
    "description": "Cluster computing system for processing large-scale spatial data."
  },
  {
    "name": "Spark-Timeseries ",
    "url": "https://github.com/cloudera/spark-timeseries",
    "description": "Scala / Java / Python library for interacting with time series data on Apache Spark."
  },
  {
    "name": "flint ",
    "url": "https://github.com/twosigma/flint",
    "description": "A time series library for Apache Spark."
  },
  {
    "name": "Mazerunner ",
    "url": "https://github.com/neo4j-contrib/neo4j-mazerunner",
    "description": "Graph analytics platform on top of Neo4j and GraphX."
  },
  {
    "name": "GraphFrames ",
    "url": "https://github.com/graphframes/graphframes",
    "description": "Data frame based graph API."
  },
  {
    "name": "neo4j-spark-connector ",
    "url": "https://github.com/neo4j-contrib/neo4j-spark-connector",
    "description": "Bolt protocol based, Neo4j Connector with RDD, DataFrame and GraphX / GraphFrames support."
  },
  {
    "name": "SparklingGraph ",
    "url": "http://sparkling.ml",
    "description": "Library extending GraphX features with multiple functionalities useful in graph analytics (measures, generators, link prediction etc.)."
  },
  {
    "name": "Clustering4Ever  Scala and Spark API to benchmark and analyse clustering algorithms on any vectorization you can generate",
    "url": "https://github.com/Clustering4Ever/Clustering4Ever"
  },
  {
    "name": "dbscan-on-spark ",
    "url": "https://github.com/irvingc/dbscan-on-spark",
    "description": "An Implementation of the DBSCAN clustering algorithm on top of Apache Spark by irvingc and based on the paper from He, Yaobin, et al. MR-DBSCAN: a scalable MapReduce-based DBSCAN algorithm for heavily skewed data."
  },
  {
    "name": "Apache SystemML ",
    "url": "https://systemml.apache.org/",
    "description": "Declarative machine learning framework on top of Spark."
  },
  {
    "name": "Mahout Spark Bindings [status unknown]",
    "url": "https://mahout.apache.org/users/sparkbindings/home.html",
    "description": "linear algebra DSL and optimizer with R-like syntax."
  },
  {
    "name": "spark-sklearn ",
    "url": "https://github.com/databricks/spark-sklearn",
    "description": "Scikit-learn integration with distributed model training."
  },
  {
    "name": "KeystoneML",
    "url": "http://keystone-ml.org/",
    "description": "Type safe machine learning pipelines with RDDs."
  },
  {
    "name": "JPMML-Spark ",
    "url": "https://github.com/jpmml/jpmml-spark",
    "description": "PMML transformer library for Spark ML."
  },
  {
    "name": "Distributed Keras ",
    "url": "https://github.com/cerndb/dist-keras",
    "description": "Distributed deep learning framework with PySpark and Keras."
  },
  {
    "name": "ModelDB ",
    "url": "https://mitdbg.github.io/modeldb",
    "description": "A system to manage machine learning models for spark.ml and scikit-learn ."
  },
  {
    "name": "Sparkling Water ",
    "url": "https://github.com/h2oai/sparkling-water",
    "description": " H2O interoperability layer."
  },
  {
    "name": "BigDL ",
    "url": "https://github.com/intel-analytics/BigDL",
    "description": "Distributed Deep Learning library."
  },
  {
    "name": "MLeap ",
    "url": "https://github.com/combust/mleap",
    "description": "Execution engine and serialization format which supports deployment of o.a.s.ml models without dependency on SparkSession."
  },
  {
    "name": "Livy ",
    "url": "https://github.com/apache/incubator-livy",
    "description": "REST server with extensive language support (Python, R, Scala), ability to maintain interactive sessions and object sharing."
  },
  {
    "name": "spark-jobserver ",
    "url": "https://github.com/spark-jobserver/spark-jobserver",
    "description": "Simple Spark as a Service which supports objects sharing using so called named objects. JVM only."
  },
  {
    "name": "Mist ",
    "url": "https://github.com/Hydrospheredata/mist",
    "description": "Service for exposing Spark analytical jobs and machine learning models as realtime, batch or reactive web services."
  },
  {
    "name": "Apache Toree ",
    "url": "https://github.com/apache/incubator-toree",
    "description": "IPython protocol based middleware for interactive applications."
  },
  {
    "name": "Kyuubi ",
    "url": "https://github.com/yaooqinn/kyuubi",
    "description": "Improved implementation of Thrift JDBC/ODBC Serve."
  },
  {
    "name": "Data Mechanics Delight ",
    "url": "https://github.com/datamechanics/delight",
    "description": "Cross-platform monitoring tool (Spark UI / Spark History Server replacement)."
  },
  {
    "name": "silex ",
    "url": "https://github.com/willb/silex",
    "description": "Collection of tools varying from ML extensions to additional RDD methods."
  },
  {
    "name": "sparkly ",
    "url": "https://github.com/Tubular/sparkly",
    "description": "Helpers & syntactic sugar for PySpark."
  },
  {
    "name": "pyspark-stubs ",
    "url": "https://github.com/zero323/pyspark-stubs",
    "description": "Static type annotations for PySpark (obsolete since Spark 3.1. See SPARK-32681)."
  },
  {
    "name": "Flintrock ",
    "url": "https://github.com/nchammas/flintrock",
    "description": "A command-line tool for launching Spark clusters on EC2."
  },
  {
    "name": "Optimus ",
    "url": "https://github.com/ironmussa/Optimus/",
    "description": "Data Cleansing and Exploration utilities with the goal of simplifying data cleaning."
  },
  {
    "name": "spark-corenlp ",
    "url": "https://github.com/databricks/spark-corenlp",
    "description": "DataFrame wrapper for Stanford CoreNLP."
  },
  {
    "name": "spark-nlp ",
    "url": "https://github.com/JohnSnowLabs/spark-nlp",
    "description": "Natural language processing library built on top of Apache Spark ML."
  },
  {
    "name": "Apache Bahir ",
    "url": "https://bahir.apache.org/",
    "description": "Collection of the streaming connectors excluded from Spark 2.0 (Akka, MQTT, Twitter. ZeroMQ)."
  },
  {
    "name": "Apache Beam ",
    "url": "https://beam.apache.org/",
    "description": "Unified data processing engine supporting both batch and streaming applications. Apache Spark is one of the supported execution environments."
  },
  {
    "name": "Blaze ",
    "url": "https://github.com/blaze/blaze",
    "description": "Interface for querying larger than memory datasets using Pandas-like syntax. It supports both Spark DataFrames and RDDs."
  },
  {
    "name": "Koalas ",
    "url": "https://github.com/databricks/koalas",
    "description": "Pandas DataFrame API on top of Apache Spark."
  },
  {
    "name": "deequ ",
    "url": "https://github.com/awslabs/deequ",
    "description": "Deequ is a library built on top of Apache Spark for defining \"unit tests for data\", which measure data quality in large datasets."
  },
  {
    "name": "spark-testing-base ",
    "url": "https://github.com/holdenk/spark-testing-base",
    "description": "Collection of base test classes."
  },
  {
    "name": "spark-fast-tests ",
    "url": "https://github.com/MrPowers/spark-fast-tests",
    "description": "A lightweight and fast testing framework."
  },
  {
    "name": "Archives Unleashed Toolkit ",
    "url": "https://github.com/archivesunleashed/aut",
    "description": " Open-source toolkit for analyzing web archives."
  },
  {
    "name": "Cromwell ",
    "url": "https://github.com/broadinstitute/cromwell#spark-backend",
    "description": "Workflow management system with Spark backend."
  },
  {
    "name": "Learning Spark, Lightning-Fast Big Data Analysis",
    "url": "http://shop.oreilly.com/product/0636920028512.do",
    "description": "Slightly outdated (Spark 1.3) introduction to Spark API. Good source of knowledge about basic concepts."
  },
  {
    "name": "Advanced Analytics with Spark",
    "url": "http://shop.oreilly.com/product/0636920035091.do",
    "description": "Useful collection of Spark processing patterns. Accompanying GitHub repository: sryza/aas."
  },
  {
    "name": "Mastering Apache Spark",
    "url": "https://jaceklaskowski.gitbooks.io/mastering-apache-spark/",
    "description": "Interesting compilation of notes by Jacek Laskowski. Focused on different aspects of Spark internals."
  },
  {
    "name": "Spark Gotchas",
    "url": "https://github.com/awesome-spark/spark-gotchas",
    "description": "Subjective compilation of tips, tricks and common programming mistakes."
  },
  {
    "name": "Spark in Action",
    "url": "https://www.manning.com/books/spark-in-action",
    "description": "New book in the Manning's \"in action\" family with +400 pages. Starts gently, step-by-step and covers large number of topics. Free excerpt on how to setup Eclipse for Spark application development and how to bootstrap a new application using the provided Maven Archetype. You can find the accompanying GitHub repo here."
  },
  {
    "name": "Large-Scale Intelligent Microservices",
    "url": "https://arxiv.org/pdf/2009.08044.pdf",
    "description": "Microsoft paper that presents an Apache Spark-based micro-service orchestration framework that extends database operations to include web service primitives."
  },
  {
    "name": "Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing",
    "url": "https://people.csail.mit.edu/matei/papers/2012/nsdi_spark.pdf",
    "description": "Paper introducing a core distributed memory abstraction."
  },
  {
    "name": "Spark SQL: Relational Data Processing in Spark",
    "url": "https://amplab.cs.berkeley.edu/wp-content/uploads/2015/03/SparkSQLSigmod2015.pdf",
    "description": "Paper introducing relational underpinnings, code generation and Catalyst optimizer."
  },
  {
    "name": "Structured Streaming: A Declarative API for Real-Time\nApplications in Apache Spark",
    "url": "https://cs.stanford.edu/~matei/papers/2018/sigmod_structured_streaming.pdf",
    "description": "Structured Streaming is a new high-level streaming API, it is a declarative API based on automatically incrementalizing a static relational query."
  },
  {
    "name": "Data Science and Engineering with Apache Spark (edX XSeries)",
    "url": "https://www.edx.org/xseries/data-science-engineering-apache-spark",
    "description": "Series of five courses (Introduction to Apache Spark, Distributed Machine Learning with Apache Spark, Big Data Analysis with Apache Spark, Advanced Apache Spark for Data Science and Data Engineering, Advanced Distributed Machine Learning with Apache Spark) covering different aspects of software engineering and data science. Python oriented."
  },
  {
    "name": "Big Data Analysis with Scala and Spark (Coursera)",
    "url": "https://www.coursera.org/learn/big-data-analysys",
    "description": "Scala oriented introductory course. Part of Functional Programming in Scala Specialization."
  },
  {
    "name": "AMP Camp",
    "url": "http://ampcamp.berkeley.edu",
    "description": "Periodical training event organized by the UC Berkeley AMPLab. A source of useful exercise and recorded workshops covering different tools from the Berkeley Data Analytics Stack."
  },
  {
    "name": "Oryx 2",
    "url": "https://github.com/OryxProject/oryx",
    "description": "Lambda architecture platform built on Apache Spark and Apac"
  }
]
